{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: pymorphy2 in c:\\programdata\\anaconda3\\lib\\site-packages (0.8)\nRequirement already satisfied: docopt>=0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\nRequirement already satisfied: dawg-python>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\nRequirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.393442.3710985)\n"
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, namedtuple\n",
    "import pymorphy2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "USEFUL_POS = ['NOUN', 'ADJF', 'ADJS', 'COMP',\n",
    "              'VERB', 'INFN', 'PRTF', 'PRTS', \n",
    "              'GRND', 'ADVB', 'NPRO', 'PRED']\n",
    "\n",
    "Stats = namedtuple(\"Stats\", \"vocabulary, lemma_vocabulary, words_counts, unique_words_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_statistics(data, max_words):\n",
    "    pm = pymorphy2.MorphAnalyzer()\n",
    "    stats = Stats(Counter(),  Counter(), list(), list())\n",
    "    for text in data:\n",
    "        process_text(text, stats, max_words, pm)\n",
    "    return stats\n",
    "\n",
    "\n",
    "def process_text(text, text_stats, max_words, analyzer):\n",
    "    words = [word.text for word in razdel.tokenize(text)][:max_words]\n",
    "    lemmas = [analyzer.parse(word)[0] for word in words]\n",
    "    lemmas = [lemma for lemma in lemmas if lemma.tag.POS in USEFUL_POS]\n",
    "    words = [lemma.word for lemma in lemmas]\n",
    "    lemmas = [lemma.normal_form for lemma in lemmas]\n",
    "    text_stats.vocabulary.update(words)\n",
    "    text_stats.lemma_vocabulary.update(lemmas)\n",
    "    text_stats.words_counts.append(len(words))\n",
    "    text_stats.unique_words_counts.append(len(set(words)))\n",
    "\n",
    "\n",
    "def draw_stat_hists(data, bins=10, label=None):\n",
    "    words = data.words_counts\n",
    "    uwords = data.unique_words_counts\n",
    "    if label is not None:\n",
    "        label = \" in single \" + label\n",
    "    else:\n",
    "        label = \"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "    ax1.hist(words, bins)\n",
    "    ax1.set_title(\"Words\" + label)\n",
    "    ax1.set_xlabel(\"Num of words\")\n",
    "    ax1.set_ylabel(\"Examples\")\n",
    "    ax2.hist(uwords, bins)\n",
    "    ax2.set_title(\"Unique words\" + label)\n",
    "    ax2.set_xlabel(\"Num of words\")\n",
    "    ax2.set_ylabel(\"Examples\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 30000\n",
    "indices = np.random.randint(len(cleaned_dataset), size=examples)\n",
    "text_data = cleaned_dataset['Text'].values[indices]\n",
    "header_data = cleaned_dataset['Head_title'].values[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_stats = collect_statistics(text_data, max_words=3000)\n",
    "header_stats = collect_statistics(header_data, max_words=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Texts vocabulary size: \", len(text_stats.vocabulary))\n",
    "print(\"Texts lemma vocabulary size: \", len(text_stats.lemma_vocabulary))\n",
    "print(\"Headers vocabulary size: \", len(header_stats.vocabulary))\n",
    "print(\"Headers lemma vocabulary size: \", len(header_stats.lemma_vocabulary))\n",
    "print(\"Common lemmas headers vs texts: \", len(set(header_stats.lemma_vocabulary.keys()) & set(text_stats.lemma_vocabulary.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stats.lemma_vocabulary.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_stats.lemma_vocabulary.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_stat_hists(text_stats, 50, label='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_stat_hists(header_stats, 10, label='header')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda0734b438104847bf97960a35e7cbfc8a",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}