{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our summarization task we would use our second dataset that contains 134010 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('/content/drive/My Drive/RusPaper/RG01.json')\n",
    "df2 = pd.read_json('/content/drive/My Drive/RusPaper/RG02.json')\n",
    "df3 = pd.read_json('/content/drive/My Drive/RusPaper/RG03.json')\n",
    "df4 = pd.read_json('/content/drive/My Drive/RusPaper/RG04.json')\n",
    "df5 = pd.read_json('/content/drive/My Drive/RusPaper/RG05.json')\n",
    "df6 = pd.read_json('/content/drive/My Drive/RusPaper/RG06.json')\n",
    "df7 = pd.read_json('/content/drive/My Drive/RusPaper/RG07.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([df1, df2, df3, df4, df5, df6, df7])\n",
    "print(\"Total lines in base dataframe:\", len(full_data))\n",
    "print(\"Total duplicated lines:\", len(full_data[full_data.duplicated(keep='first')]))\n",
    "df = full_data.drop_duplicates()\n",
    "print(\"Total unique lines in cleaned dataframe:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a first look at our data common stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have 105 Null cells in Text column in dataframe that was not collected automatically due to specific of html and css formatting of some special news pages. And secondly we see 137 empty cells which must contain news titles. Let's get only lines that are full of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Text'].notna()]\n",
    "df = df[df['Head_title'].notna()]\n",
    "print(\"Total unique lines in final dataframe:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Date_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sort our data for DateTime. When dividing data to training set and a test set, earlier data should put to the training set for preserving the time series.\n",
    "Now we have 603 lines that contains \"0001-01-01T00:00:00\" DateTime value. This happened during parsing process, when some news hadn't got any time stamps. Min value DateTime was automatically added. These lines represent only 0.5% of the total data set, save them too.\n",
    "\n",
    "After all for our summarization task we don't need any column except \"Text\" that to be used as inputs and \"Head_title\" that to be used as targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Article_id', 'Url', 'Date_time', 'Head_rubric', 'Head_subtitle', 'Keywords', 'Authors'], axis=1)\n",
    "cleaned_dataset = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.to_json('cleaned_dataset.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}