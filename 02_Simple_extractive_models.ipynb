{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge razdel pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils: score calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Last true headline:\", references[-1])\n",
    "    print(\"Last predicted headline:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"\\nBLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        scores_string = \"\"\n",
    "        for metric, value in scores.items():\n",
    "            scores_string += \"\\n\" + str(metric) + \":\" + str(value)\n",
    "        print(\"ROUGE: \", scores_string, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model is FSDE aka first sentence dumb extractor.\n",
    "\n",
    "Our hypothesis is that in many news the first sentence of text already contains the most important summary. From the good literacy, that kind of duplication in the title looks silly, but as a baseline method we want to check what metrics it can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_FSDE_score(data, lower=True):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for text, title in tqdm(data[['Text', 'Head_title']].values):\n",
    "        title = title if not lower else title.lower()\n",
    "        references.append(title)\n",
    "\n",
    "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "        sentences[:] = [s if not lower else s.lower() for s in sentences]\n",
    "        prediction = \" \".join(sentences[:1])\n",
    "        predictions.append(prediction)\n",
    "    calc_scores(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_FSDE_score(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selfdesigned TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words_similarity(words1, words2):\n",
    "    '''\n",
    "    Функция подсчёта близости предложений на основе пересечения слов\n",
    "    ''' \n",
    "    words1 = set(words1)\n",
    "    words2 = set(words2)\n",
    "    if not len(words1) or not len(words2):\n",
    "        return 0.0\n",
    "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
    "\n",
    "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.2, lower=True, morph=None):\n",
    "    '''\n",
    "    Составление summary с помощью TextRank\n",
    "    '''\n",
    "    # Разбиваем текст на предложения\n",
    "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Токенизируем предложения\n",
    "    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
    "\n",
    "    # При необходимости лемматизируем слова\n",
    "    if morph is not None:\n",
    "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
    "\n",
    "    # Для каждой пары предложений считаем близость\n",
    "    pairs = combinations(range(n_sentences), 2)\n",
    "    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
    "\n",
    "    # Строим граф с рёбрами, равными близости между предложениями\n",
    "    g = nx.Graph()\n",
    "    g.add_weighted_edges_from(scores)\n",
    "\n",
    "    # Считаем PageRank\n",
    "    pr = nx.pagerank(g)\n",
    "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
    "    result.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Выбираем топ предложений\n",
    "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
    "    result = result[:1]\n",
    "    #result = result[:n_summary_sentences]\n",
    "\n",
    "    # Восстанавливаем оригинальный их порядок\n",
    "    result.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Восстанавливаем текст выжимки\n",
    "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
    "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
    "    return predicted_summary\n",
    "\n",
    "def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for text, title in tqdm(records[['Text', 'Head_title']].values):\n",
    "        title = title if not lower else title.lower()\n",
    "        references.append(title)\n",
    "\n",
    "        predicted_title = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
    "        text = text if not lower else text.lower()\n",
    "        predictions.append(predicted_title)\n",
    "\n",
    "    calc_scores(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_text_rank_score(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second version uses MorphAnalyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_text_rank_score(cleaned_dataset, morph=pymorphy2.MorphAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
    "    '''\n",
    "    Жадное построение oracle summary\n",
    "    '''\n",
    "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
    "    # Делим текст на предложения\n",
    "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
    "    n_sentences = len(sentences)\n",
    "    oracle_summary_sentences = set()\n",
    "    score = -1.0\n",
    "    summaries = []\n",
    "    for _ in range(min(n_sentences, 2)):\n",
    "        for i in range(n_sentences):\n",
    "            if i in oracle_summary_sentences:\n",
    "                continue\n",
    "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
    "            # Добавляем какое-то предложения к уже существующему summary\n",
    "            current_summary_sentences.add(i)\n",
    "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
    "            # Считаем метрики\n",
    "            current_score = calc_score(current_summary, gold_summary)\n",
    "            summaries.append((current_score, current_summary_sentences))\n",
    "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
    "        # Иначе на этом заканчиваем\n",
    "        best_summary_score, best_summary_sentences = max(summaries)\n",
    "        if best_summary_score <= score:\n",
    "            break\n",
    "        oracle_summary_sentences = best_summary_sentences\n",
    "        score = best_summary_score\n",
    "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
    "    return oracle_summary, oracle_summary_sentences\n",
    "\n",
    "\n",
    "def calc_single_score(pred_summary, gold_summary, rouge):\n",
    "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']\n",
    "\n",
    "\n",
    "def calc_oracle_score(records, nrows=30000, lower=True):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    rouge = Rouge()\n",
    "  \n",
    "    for text, title in tqdm(records[['Text', 'Head_title']].values[:nrows]):\n",
    "        title = title if not lower else title.lower()\n",
    "        references.append(title)\n",
    "        predicted_summary, _ = build_oracle_summary_greedy(text, title, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
    "        predictions.append(predicted_summary)\n",
    "\n",
    "    calc_scores(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_oracle_score(cleaned_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}